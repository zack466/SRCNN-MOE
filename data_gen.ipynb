{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to read from HR div2k images, generate 128x128 images, downscale to 64x64 and rescale to 128x128 inter.bicub\n",
    "The 128px images are ground truth and the upscaled 128px are fed into the network inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path,import_all=True,import_num=0):\n",
    "    if not import_all:\n",
    "        with h5py.File(path,'r') as file:\n",
    "            return\n",
    "    with h5py.File(path,'r') as file:\n",
    "        images = np.array(file.get('images'))\n",
    "        labels = np.array(file.get('labels'))\n",
    "    return images, labels\n",
    "\n",
    "def save_datasets(images,labels,path):\n",
    "    with h5py.File(path,'w') as file:\n",
    "        file.create_dataset(\"images\",data=images)\n",
    "        file.create_dataset(\"labels\",data=labels)\n",
    "\n",
    "def process_for_labels(image,scale=2):\n",
    "    '''\n",
    "    assumes that the image fed in is a 128x128 normalized RGB image\n",
    "    Takes in a 128px image and produces the lowres\n",
    "    '''\n",
    "    highres = image\n",
    "    height, width, channels = highres.shape\n",
    "    lowres = cv2.resize(image, (int(32./scale),int(32./scale)))\n",
    "    lowres = cv2.resize(lowres, (32,32),interpolation=cv2.INTER_CUBIC)\n",
    "    return lowres, highres\n",
    "\n",
    "def prep_data(data_path=\"F:\\div2k\\DIV2K_train_HR_32\",image_size=32):\n",
    "    #finished data is saved in .h5 files at D:/TestData/train and D:/TestData/test\n",
    "    #read in images from chunks\n",
    "    image_paths = [(data_path + \"\\\\\" + path) for path in os.listdir(data_path)]\n",
    "    #randomization of images\n",
    "    random.shuffle(image_paths)\n",
    "    for scale in range(3,5):\n",
    "        counter = 0\n",
    "        images = [] #lowres\n",
    "        labels = [] #highres\n",
    "        test_images = []\n",
    "        test_labels = []\n",
    "        #crop the images into 128px chunks, normalize them, and then turn them into image,label format\n",
    "        train_batch_counter = 0\n",
    "        test_batch_counter = 0\n",
    "        \n",
    "        if not os.path.exists(\"D:/TestData/train-x\"+str(scale)):\n",
    "            os.mkdir(\"D:/TestData/train-x\"+str(scale))\n",
    "        if not os.path.exists(\"D:/TestData/test-x\"+str(scale)):\n",
    "            os.mkdir(\"D:/TestData/test-x\"+str(scale))\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "                assert image.shape == (32,32,3)\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "                image = np.ndarray.astype(image,'float32')\n",
    "                image /= 255.\n",
    "                image, label = process_for_labels(image,scale=scale)\n",
    "                if random.randint(0,9) == 0: #roughly 0.9:0.1 train:test split\n",
    "                    #test data\n",
    "                    test_images.append(image)\n",
    "                    test_labels.append(label)\n",
    "                else:\n",
    "                    #train data\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "            if len(images) >= 4096:\n",
    "                images = np.array(images) # a list of LR images in shape (num_images,128,128,3)\n",
    "                labels = np.array(labels) # a list of HR images in shape (num_images,128,128,3)\n",
    "                save_datasets(images,labels,\"D:/TestData/train-x\"+str(scale)+\"/train_\"+str(train_batch_counter).zfill(4)+\".h5\")\n",
    "                train_batch_counter+=1\n",
    "                images = []\n",
    "                labels = []\n",
    "            if len(test_images) >= 4096:\n",
    "                test_images = np.array(test_images)\n",
    "                test_labels = np.array(test_labels)\n",
    "                save_datasets(test_images,test_labels,\"D:/TestData/test-x\"+str(scale)+\"/test_\"+str(test_batch_counter).zfill(4)+\".h5\")\n",
    "                test_batch_counter+=1\n",
    "                test_images = []\n",
    "                test_labels = []\n",
    "            \n",
    "        #store the images and labels in h5py files\n",
    "        images = np.array(images) # a list of LR images in shape (num_images,128,128,3)\n",
    "        labels = np.array(labels) # a list of HR images in shape (num_images,128,128,3)\n",
    "\n",
    "        save_datasets(images,labels,\"D:/TestData/train-x\"+str(scale)+\"/train_\"+str(train_batch_counter).zfill(4)+\".h5\")\n",
    "\n",
    "        test_images = np.array(test_images)\n",
    "        test_labels = np.array(test_labels)\n",
    "        save_datasets(test_images,test_labels,\"D:/TestData/test-x\"+str(scale)+\"/test_\"+str(test_batch_counter).zfill(4)+\".h5\")\n",
    "        print(\"it is done\")\n",
    "    \n",
    "def split_into_chunks(data_path=\"F:\\div2k\\DIV2K_train_HR\\\\\"):\n",
    "    '''reads in images from div2k splits it into 32px chunks, and saves the images in a new folder'''\n",
    "    image_paths = [(data_path + path) for path in os.listdir(data_path)]\n",
    "    counter = 0\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, channels = image.shape\n",
    "        for horizcrop in range(height//32):\n",
    "            for vertcrop in range(width//32):\n",
    "                cropped_image = image[vertcrop*32:(vertcrop+1)*32, horizcrop*32: (horizcrop+1)*32]\n",
    "                new_img_path = \"F:\\div2k\\DIV2K_train_HR_32\\\\\" + str(counter).zfill(7) + \".png\"\n",
    "                if cv2.imwrite(new_img_path,cropped_image):\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #split_into_chunks()\n",
    "    #prep_data\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

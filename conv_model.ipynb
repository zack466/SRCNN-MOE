{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import data_gen\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    # x --> [image_batch,width,height,color_channels]\n",
    "    # W --> [filter_height,filter_width,channels_in,channels_out]\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def relu(x):\n",
    "    # x --> features\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 sess,\n",
    "                 image_size,\n",
    "                 color_channels,\n",
    "                 num_convolutions = 3,\n",
    "                 filters=[[9,9,3,64],[1,1,64,32],[5,5,32,3]],\n",
    "                 bias_shapes=[[64],[32],[3]],\n",
    "                 train_data_dir=\"D:/TestData/train/\"):\n",
    "        \n",
    "        self.sess = sess\n",
    "        self.image_size = image_size\n",
    "        self.color_channels = color_channels\n",
    "        assert num_convolutions == len(filters), \"Number of convs does not match number of filters\"\n",
    "        assert len(filters) == len(bias_shapes), \"Number of filters does not match number of biases\"\n",
    "        self.num_convolutions = num_convolutions\n",
    "        self.filters = filters\n",
    "        self.bias_shapes = bias_shapes\n",
    "        self.train_data_dir = train_data_dir\n",
    "    \n",
    "    def test(self):\n",
    "        print(\"Hello world\")\n",
    "    \n",
    "    def init_bias_zero(self,shape,name):\n",
    "        return tf.Variable(tf.zeros(shape),name=name)\n",
    "    \n",
    "    def init_weights_normal(self,shape,name,stddev=0.0001):\n",
    "        return tf.Variable(tf.random_normal(shape,stddev=stddev),name=name)\n",
    "    \n",
    "    def initialize(self):\n",
    "        \n",
    "        # from https://arxiv.org/abs/1501.00092 there are filter sizes of 9-1-5 in 3 different convolutions\n",
    "        # weights shapes: [9,9,1?3,64] --> [1,1,64,32] --> [5,5,32,1?3]\n",
    "        # biases shaped [64] --> [32] --> [1?3]\n",
    "        # Best results when trained on Y-channel (c=1) only or RGB jointly (c=3)\n",
    "        \n",
    "        # initialize weights and biases\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(self.num_convolutions):\n",
    "            self.weights.append(self.init_weights_normal(self.filters[i],(\"w\"+str(i))))\n",
    "        \n",
    "        for j in range(self.num_convolutions):\n",
    "            self.biases.append(self.init_bias_zero(self.bias_shapes[j],(\"b\"+str(j))))\n",
    "        \n",
    "        default = '''\n",
    "        w1 = _init_weights_normal([9,9,3,64],\"w1\")\n",
    "        w2 = _init_weights_normal([1,1,64,32],\"w2\")\n",
    "        w3 = _init_weights_normal([5,5,32,3],\"w2\")\n",
    "        b1 = _init_bias_zero([64],\"b1\")\n",
    "        b2 = _init_bias_zero([32],\"b2\")\n",
    "        b3 = _init_bias_zero([1],\"b3\")\n",
    "        '''\n",
    "        \n",
    "        # placeholders for images (input) and the predictions (output)\n",
    "        self.images = tf.placeholder('float32',[None,image_size,image_size,color_channels],name='images')\n",
    "        self.labels = tf.placeholder('float32',[None,image_size,image_size,color_channels],name='labels')\n",
    "        \n",
    "        self.prediction = self.model(self.num_convolutions)\n",
    "        \n",
    "        # mse loss (TODO: implement SSIM)\n",
    "        self.loss = tf.reduce_mean(tf.square(self.labels - self.prediction))\n",
    "    \n",
    "    def model(self,conv):\n",
    "        test = '''\n",
    "        conv -= 1 #to match array indexes\n",
    "        if conv == 0:\n",
    "            # first convolutional layer\n",
    "            layer_first = relu(conv2d(self.images,self.weights[0]) + self.biases[0])\n",
    "            return layer_first\n",
    "        elif conv == self.num_convolutions-1:\n",
    "            # last convolutional layer (no relu)\n",
    "            layer_final = conv2d(self.model(conv-1),self.weights[conv]) + self.biases(conv)\n",
    "            return layer_final\n",
    "        else:\n",
    "            # any intermediate convolutional layers\n",
    "            layer_intermediate = relu(conv2d(self.model(conv-1),self.weights[conv]) + biases[conv])\n",
    "            return layer_intermediate\n",
    "        '''\n",
    "        conv_layer = relu(conv2d(self.images,self.weights[0]) + self.biases[0])\n",
    "        conv_layer = relu(conv2d(conv_layer,self.weights[1]) + self.biases[1])\n",
    "        conv_layer = conv2d(conv_layer,self.weights[2] + self.biases[2])\n",
    "        return conv_layer\n",
    "    \n",
    "    def train(self, batch_size=64, epochs=500):\n",
    "        train_sets = os.listdir(self.train_data_dir)\n",
    "        #TODO: reprocess data, remember to MAKE BACKUP\n",
    "        current_train_set = train_sets[0]\n",
    "        images, labels = data_gen.read_data(self.train_data_dir + current_train_set)\n",
    "        # see optimizers at https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(learning_rate=0.00001).minimize(self.loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.sess.run(init)\n",
    "        \n",
    "        steps = len(images) // batch_size\n",
    "        \n",
    "        #each epoch is a single iteration over (almost) the entire dataset batch\n",
    "        for epoch in range(epochs):\n",
    "            for step in range(steps):\n",
    "                image_batch = images[step*batch_size:(step+1)*batch_size]\n",
    "                label_batch = labels[step*batch_size:(step+1)*batch_size]\n",
    "                \n",
    "                self.sess.run(self.train_op,feed_dict={self.images:image_batch, self.labels:label_batch})\n",
    "                \n",
    "                if step % 5 == 0:\n",
    "                    loss = self.sess.run(self.loss,feed_dict={self.images:image_batch, self.labels:label_batch})\n",
    "                    print(\"Epoch: \"+str(epoch)+\", Step: \"+str(step)+\", Loss: \"+str(loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sets = os.listdir(\"D:/TestData/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_00.h5',\n",
       " 'train_01.h5',\n",
       " 'train_02.h5',\n",
       " 'train_03.h5',\n",
       " 'train_04.h5',\n",
       " 'train_05.h5',\n",
       " 'train_06.h5',\n",
       " 'train_07.h5']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/TestData/train/train_00.h5\n",
      "<KeysViewHDF5 ['images', 'labels']>\n"
     ]
    }
   ],
   "source": [
    "#print(\"D:/TestData/train/\"+train_sets[0])\n",
    "#with h5py.File(\"D:/TestData/train/\"+train_sets[2], 'r') as file:\n",
    "#    print(file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
